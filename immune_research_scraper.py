import asyncio
import aiohttp
from bs4 import BeautifulSoup
import pandas as pd
from dataclasses import dataclass
from typing import List, Optional
import time
import json
import re
from urllib.parse import urljoin, urlparse
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ResearchLab:
    """ç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿æ§‹é€ """
    university_name: str
    department: str
    lab_name: str
    professor_name: str
    research_theme: str
    research_content: str
    research_field: str
    lab_url: str
    prefecture: str
    region: str

class ImmuneResearchScraper:
    """å…ç–«ç ”ç©¶å®¤å°‚ç”¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.session = None
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Research Lab Finder Bot) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.7,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        }
        self.delay = 2  # 2ç§’é–“éš”ã§ã‚¢ã‚¯ã‚»ã‚¹
        
    async def __aenter__(self):
        """éåŒæœŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
        self.session = aiohttp.ClientSession(headers=self.headers)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.session:
            await self.session.close()
    
    async def fetch_page(self, url: str) -> Optional[str]:
        """Webãƒšãƒ¼ã‚¸ã‚’å–å¾—"""
        try:
            await asyncio.sleep(self.delay)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
            async with self.session.get(url, timeout=10) as response:
                if response.status == 200:
                    return await response.text()
                else:
                    logger.warning(f"Failed to fetch {url}: {response.status}")
                    return None
        except Exception as e:
            logger.error(f"Error fetching {url}: {e}")
            return None
    
    def extract_immune_keywords(self, text: str) -> bool:
        """å…ç–«é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œå‡º"""
        immune_keywords = [
            'å…ç–«', 'immunity', 'immunology', 'immune',
            'Tç´°èƒ', 'Bç´°èƒ', 'NKç´°èƒ', 'ãƒã‚¯ãƒ­ãƒ•ã‚¡ãƒ¼ã‚¸',
            'ã‚µã‚¤ãƒˆã‚«ã‚¤ãƒ³', 'ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ­ãƒ³', 'ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ­ã‚¤ã‚­ãƒ³',
            'æŠ—ä½“', 'antibody', 'antigen', 'æŠ—åŸ',
            'ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼', 'allergy', 'ã‚¢ãƒˆãƒ”ãƒ¼',
            'è‡ªå·±å…ç–«', 'autoimmune', 'autoimmunity',
            'ãƒ¯ã‚¯ãƒãƒ³', 'vaccine', 'äºˆé˜²æ¥ç¨®',
            'ãŒã‚“å…ç–«', 'cancer immunotherapy',
            'ç‚ç—‡', 'inflammation', 'inflammatory'
        ]
        
        text_lower = text.lower()
        return any(keyword.lower() in text_lower for keyword in immune_keywords)
    
    async def scrape_university_labs(self, university_config: dict) -> List[ResearchLab]:
        """å¤§å­¦ã®ç ”ç©¶å®¤æƒ…å ±ã‚’å–å¾—"""
        labs = []
        
        # å¤§å­¦ã‚µã‚¤ãƒˆã®æ§‹é€ ã«å¿œã˜ãŸã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
        for url in university_config['urls']:
            html = await self.fetch_page(url)
            if not html:
                continue
                
            soup = BeautifulSoup(html, 'html.parser')
            
            # å„å¤§å­¦ã®HTMLæ§‹é€ ã«å¿œã˜ãŸè§£æ
            lab_elements = self.find_lab_elements(soup, university_config)
            
            for element in lab_elements:
                lab_data = self.extract_lab_data(element, university_config)
                if lab_data and self.extract_immune_keywords(lab_data.research_content):
                    labs.append(lab_data)
                    logger.info(f"Found immune lab: {lab_data.lab_name}")
        
        return labs
    
    def find_lab_elements(self, soup: BeautifulSoup, config: dict) -> List:
        """ç ”ç©¶å®¤è¦ç´ ã‚’æ¢ã™ï¼ˆå¤§å­¦ã”ã¨ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼‰"""
        # ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™
        selectors = [
            '.lab-item', '.research-lab', '.professor-info',
            '.faculty-member', '.lab-info', '.research-group'
        ]
        
        for selector in selectors:
            elements = soup.select(selector)
            if elements:
                return elements
        
        # ã‚¿ã‚°ãƒ™ãƒ¼ã‚¹ã§ã®æ¤œç´¢
        return soup.find_all(['div', 'section'], class_=re.compile(r'lab|research|professor'))
    
    def extract_lab_data(self, element, config: dict) -> Optional[ResearchLab]:
        """è¦ç´ ã‹ã‚‰ç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        try:
            # åŸºæœ¬æƒ…å ±ã®æŠ½å‡ºï¼ˆã“ã‚Œã¯å®Ÿéš›ã®HTMLæ§‹é€ ã«å¿œã˜ã¦èª¿æ•´ãŒå¿…è¦ï¼‰
            lab_name = self.extract_text(element, ['.lab-name', '.title', 'h2', 'h3'])
            professor_name = self.extract_text(element, ['.professor', '.name', '.faculty-name'])
            research_content = self.extract_text(element, ['.research', '.description', '.content', 'p'])
            
            if not lab_name or not research_content:
                return None
            
            return ResearchLab(
                university_name=config['name'],
                department=config.get('department', ''),
                lab_name=lab_name,
                professor_name=professor_name or '',
                research_theme=lab_name,  # ä»®è¨­å®š
                research_content=research_content,
                research_field='å…ç–«å­¦',
                lab_url=config.get('base_url', ''),
                prefecture=config.get('prefecture', ''),
                region=config.get('region', '')
            )
        except Exception as e:
            logger.error(f"Error extracting lab data: {e}")
            return None
    
    def extract_text(self, element, selectors: List[str]) -> str:
        """æŒ‡å®šã•ã‚ŒãŸã‚»ãƒ¬ã‚¯ã‚¿ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
        for selector in selectors:
            found = element.select_one(selector)
            if found:
                return found.get_text(strip=True)
        return ''

# å®Ÿéš›ã®èª¿æŸ»çµæœã«åŸºã¥ãå¤§å­¦è¨­å®šãƒ‡ãƒ¼ã‚¿
UNIVERSITY_CONFIGS = [
    {
        'name': 'å¤§é˜ªå¤§å­¦',
        'department': 'å…ç–«å­¦ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼',
        'prefecture': 'å¤§é˜ªåºœ',
        'region': 'é–¢è¥¿',
        'urls': [
            'https://www.ifrec.osaka-u.ac.jp/jpn/laboratory/',  # ç ”ç©¶ã‚°ãƒ«ãƒ¼ãƒ—ä¸€è¦§
        ],
        'base_url': 'https://www.ifrec.osaka-u.ac.jp/',
        'type': 'ifrec_format',  # ç‰¹åˆ¥ãªè§£æå½¢å¼
        'research_groups': 24  # 24ã®ç ”ç©¶ã‚°ãƒ«ãƒ¼ãƒ—
    },
    {
        'name': 'æ¨ªæµœå¸‚ç«‹å¤§å­¦',
        'department': 'åŒ»å­¦ç ”ç©¶ç§‘',
        'prefecture': 'ç¥å¥ˆå·çœŒ',
        'region': 'é–¢æ±',
        'urls': [
            'https://www-user.yokohama-cu.ac.jp/~immunol/',
        ],
        'base_url': 'https://www-user.yokohama-cu.ac.jp/',
        'type': 'ycu_format',
        'professor': 'ç”°æ‘æ™ºå½¦',  # è«–æ–‡å¼•ç”¨åº¦1ä½
        'speciality': 'æ¨¹çŠ¶ç´°èƒç ”ç©¶'
    },
    {
        'name': 'æ±äº¬å¤§å­¦',
        'department': 'åŒ»å­¦éƒ¨å…ç–«å­¦æ•™å®¤',
        'prefecture': 'æ±äº¬éƒ½',
        'region': 'é–¢æ±',
        'urls': [
            'http://www.osteoimmunology.com/',  # é«˜æŸ³ç ”ç©¶å®¤
            'http://www.immunol.m.u-tokyo.ac.jp/',
        ],
        'base_url': 'http://www.immunol.m.u-tokyo.ac.jp/',
        'type': 'utokyo_format',
        'professor': 'é«˜æŸ³åºƒ',
        'speciality': 'éª¨å…ç–«å­¦'
    },
    {
        'name': 'ç­‘æ³¢å¤§å­¦',
        'department': 'åŒ»å­¦åŒ»ç™‚ç³»',
        'prefecture': 'èŒ¨åŸçœŒ',
        'region': 'é–¢æ±',
        'urls': [
            'http://immuno-tsukuba.com/',
        ],
        'base_url': 'http://immuno-tsukuba.com/',
        'type': 'tsukuba_format',
        'professor': 'æ¸‹è°·å½°',
        'speciality': 'NKç´°èƒç ”ç©¶'
    },
    {
        'name': 'åå¤å±‹å¤§å­¦',
        'department': 'åŒ»å­¦ç³»ç ”ç©¶ç§‘',
        'prefecture': 'æ„›çŸ¥çœŒ',
        'region': 'æ±æµ·',
        'urls': [
            'https://www.med.nagoya-u.ac.jp/medical_J/laboratory/basic-med/micro-immunology/immunology/',
        ],
        'base_url': 'https://www.med.nagoya-u.ac.jp/',
        'type': 'nagoya_format',
        'speciality': 'ãŒã‚“å…ç–«å­¦'
    },
]

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå®Ÿéš›ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®ä»£æ›¿ï¼‰
def generate_sample_immune_labs() -> List[ResearchLab]:
    """å…ç–«ç ”ç©¶ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ"""
    sample_labs = [
        ResearchLab(
            university_name="æ±äº¬å¤§å­¦",
            department="åŒ»å­¦éƒ¨",
            lab_name="å…ç–«åˆ¶å¾¡å­¦æ•™å®¤",
            professor_name="ç”°ä¸­å¤ªéƒ",
            research_theme="Tç´°èƒå…ç–«å¿œç­”ã®åˆ¶å¾¡æ©Ÿæ§‹",
            research_content="Tç´°èƒã®åˆ†åŒ–ã¨æ©Ÿèƒ½åˆ¶å¾¡ã€ç‰¹ã«åˆ¶å¾¡æ€§Tç´°èƒï¼ˆTregï¼‰ã®æ©Ÿèƒ½è§£æã‚’é€šã˜ã¦ã€è‡ªå·±å…ç–«ç–¾æ‚£ã‚„ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼ç–¾æ‚£ã®ç—…æ…‹è§£æ˜ã¨æ²»ç™‚æ³•é–‹ç™ºã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ãŒã‚“å…ç–«ç™‚æ³•ã«ãŠã‘ã‚‹å…ç–«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé˜»å®³å‰¤ã®ä½œç”¨æ©Ÿåºã«ã¤ã„ã¦ã‚‚ç ”ç©¶ã—ã¦ã„ã¾ã™ã€‚",
            research_field="å…ç–«å­¦",
            lab_url="https://www.m.u-tokyo.ac.jp/immunology/",
            prefecture="æ±äº¬éƒ½",
            region="é–¢æ±"
        ),
        ResearchLab(
            university_name="äº¬éƒ½å¤§å­¦",
            department="åŒ»å­¦éƒ¨",
            lab_name="æ„ŸæŸ“å…ç–«å­¦åˆ†é‡",
            professor_name="ä½è—¤èŠ±å­",
            research_theme="æ„ŸæŸ“ç—‡ã«å¯¾ã™ã‚‹å…ç–«å¿œç­”æ©Ÿæ§‹",
            research_content="ã‚¦ã‚¤ãƒ«ã‚¹æ„ŸæŸ“ã«å¯¾ã™ã‚‹è‡ªç„¶å…ç–«ãŠã‚ˆã³ç²å¾—å…ç–«ã®å¿œç­”æ©Ÿæ§‹ã‚’è§£æã—ã€æ–°ã—ã„ãƒ¯ã‚¯ãƒãƒ³é–‹ç™ºã‚„æŠ—ã‚¦ã‚¤ãƒ«ã‚¹ç™‚æ³•ã®åŸºç›¤ã¨ãªã‚‹ç ”ç©¶ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚ç‰¹ã«ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚¶ã‚¦ã‚¤ãƒ«ã‚¹ã‚„ã‚³ãƒ­ãƒŠã‚¦ã‚¤ãƒ«ã‚¹ã«å¯¾ã™ã‚‹å…ç–«è¨˜æ†¶ã®å½¢æˆæ©Ÿæ§‹ã«æ³¨ç›®ã—ã¦ã„ã¾ã™ã€‚",
            research_field="å…ç–«å­¦",
            lab_url="https://www.med.kyoto-u.ac.jp/infection-immunology/",
            prefecture="äº¬éƒ½åºœ",
            region="é–¢è¥¿"
        ),
        ResearchLab(
            university_name="å¤§é˜ªå¤§å­¦",
            department="å…ç–«å­¦ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼",
            lab_name="åˆ†å­å…ç–«å­¦ç ”ç©¶å®¤",
            professor_name="å±±ç”°æ¬¡éƒ",
            research_theme="è‡ªç„¶å…ç–«å—å®¹ä½“ã®æ©Ÿèƒ½è§£æ",
            research_content="Tollæ§˜å—å®¹ä½“ï¼ˆTLRï¼‰ã‚’ã¯ã˜ã‚ã¨ã™ã‚‹è‡ªç„¶å…ç–«å—å®¹ä½“ã®åˆ†å­æ©Ÿæ§‹ã‚’è§£æã—ã€ç‚ç—‡æ€§ç–¾æ‚£ã‚„è‡ªå·±å…ç–«ç–¾æ‚£ã®ç—…æ…‹è§£æ˜ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ã“ã‚Œã‚‰ã®å—å®¹ä½“ã‚’æ¨™çš„ã¨ã—ãŸæ–°è¦æ²»ç™‚è–¬ã®é–‹ç™ºã‚‚è¡Œã£ã¦ã„ã¾ã™ã€‚",
            research_field="å…ç–«å­¦",
            lab_url="https://www.ifrec.osaka-u.ac.jp/molecular-immunology/",
            prefecture="å¤§é˜ªåºœ",
            region="é–¢è¥¿"
        )
    ]
    
    # ã‚ˆã‚Šå¤šãã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    research_themes = [
        ("ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼å…ç–«å­¦", "ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼åå¿œã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ è§£æ˜ã¨æ²»ç™‚æ³•é–‹ç™º"),
        ("ãŒã‚“å…ç–«å­¦", "å…ç–«ç³»ã«ã‚ˆã‚‹ãŒã‚“ç´°èƒã®èªè­˜ã¨æ’é™¤æ©Ÿæ§‹ã®ç ”ç©¶"),
        ("è‡ªå·±å…ç–«å­¦", "è‡ªå·±å…ç–«ç–¾æ‚£ã®ç™ºç—‡æ©Ÿæ§‹ã¨å…ç–«å¯›å®¹ã®ç¶­æŒ"),
        ("ãƒ¯ã‚¯ãƒãƒ³å­¦", "åŠ¹æœçš„ãªãƒ¯ã‚¯ãƒãƒ³è¨­è¨ˆã¨å…ç–«è¨˜æ†¶ã®å½¢æˆ"),
        ("ç²˜è†œå…ç–«å­¦", "è…¸ç®¡å…ç–«ç³»ã¨æ„ŸæŸ“é˜²å¾¡æ©Ÿæ§‹ã®ç ”ç©¶"),
        ("å…ç–«è€åŒ–å­¦", "åŠ é½¢ã«ä¼´ã†å…ç–«æ©Ÿèƒ½ã®å¤‰åŒ–ã¨ç–¾æ‚£ã¨ã®é–¢é€£"),
        ("ç§»æ¤å…ç–«å­¦", "è‡“å™¨ç§»æ¤ã«ãŠã‘ã‚‹å…ç–«æ‹’çµ¶åå¿œã®åˆ¶å¾¡"),
        ("å…ç–«ä»£è¬å­¦", "å…ç–«ç´°èƒã®ä»£è¬ã¨æ©Ÿèƒ½ã®ç›¸é–¢é–¢ä¿‚"),
    ]
    
    universities = [
        ("æ…¶æ‡‰ç¾©å¡¾å¤§å­¦", "åŒ»å­¦éƒ¨", "æ±äº¬éƒ½", "é–¢æ±"),
        ("æ—©ç¨²ç”°å¤§å­¦", "å…ˆé€²ç†å·¥å­¦éƒ¨", "æ±äº¬éƒ½", "é–¢æ±"),
        ("åŒ—æµ·é“å¤§å­¦", "åŒ»å­¦éƒ¨", "åŒ—æµ·é“", "åŒ—æµ·é“"),
        ("æ±åŒ—å¤§å­¦", "åŒ»å­¦éƒ¨", "å®®åŸçœŒ", "æ±åŒ—"),
        ("åå¤å±‹å¤§å­¦", "åŒ»å­¦éƒ¨", "æ„›çŸ¥çœŒ", "æ±æµ·"),
        ("ä¹å·å¤§å­¦", "åŒ»å­¦éƒ¨", "ç¦å²¡çœŒ", "ä¹å·"),
    ]
    
    for i, (theme, content) in enumerate(research_themes):
        univ_info = universities[i % len(universities)]
        sample_labs.append(
            ResearchLab(
                university_name=univ_info[0],
                department=univ_info[1],
                lab_name=f"{theme}ç ”ç©¶å®¤",
                professor_name=f"æ•™æˆ{i+4}",
                research_theme=theme,
                research_content=f"{content}ã‚’ä¸­å¿ƒã¨ã—ãŸç ”ç©¶ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚åˆ†å­ãƒ¬ãƒ™ãƒ«ã‹ã‚‰å€‹ä½“ãƒ¬ãƒ™ãƒ«ã¾ã§ã®å¤šè§’çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€å…ç–«ã‚·ã‚¹ãƒ†ãƒ ã®ç†è§£ã‚’æ·±ã‚ã€æ–°ã—ã„æ²»ç™‚æˆ¦ç•¥ã®é–‹ç™ºã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚",
                research_field="å…ç–«å­¦",
                lab_url=f"https://{univ_info[0].lower()}.ac.jp/immunology{i+1}/",
                prefecture=univ_info[2],
                region=univ_info[3]
            )
        )
    
    return sample_labs

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”¬ å…ç–«ç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")
    
    # å®Ÿéš›ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆå®Ÿè£…ä¾‹ï¼‰
    # async with ImmuneResearchScraper() as scraper:
    #     all_labs = []
    #     for config in UNIVERSITY_CONFIGS:
    #         labs = await scraper.scrape_university_labs(config)
    #         all_labs.extend(labs)
    #         print(f"âœ… {config['name']}: {len(labs)} labs found")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ä½¿ç”¨ï¼ˆé–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç”¨ï¼‰
    all_labs = generate_sample_immune_labs()
    print(f"ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(all_labs)} ç ”ç©¶å®¤")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
    df = pd.DataFrame([
        {
            'university_name': lab.university_name,
            'department': lab.department,
            'lab_name': lab.lab_name,
            'professor_name': lab.professor_name,
            'research_theme': lab.research_theme,
            'research_content': lab.research_content,
            'research_field': lab.research_field,
            'lab_url': lab.lab_url,
            'prefecture': lab.prefecture,
            'region': lab.region
        }
        for lab in all_labs
    ])
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    df.to_csv('immune_research_labs.csv', index=False, encoding='utf-8')
    print("ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ 'immune_research_labs.csv' ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    print("\nğŸ“ˆ åé›†ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
    print(f"- ç ”ç©¶å®¤æ•°: {len(df)}")
    print(f"- å¤§å­¦æ•°: {df['university_name'].nunique()}")
    print(f"- åœ°åŸŸåˆ†å¸ƒ: {df['region'].value_counts().to_dict()}")
    
    return df

if __name__ == "__main__":
    # ã‚µãƒ³ãƒ—ãƒ«å®Ÿè¡Œ
    asyncio.run(main())