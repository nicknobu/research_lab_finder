"""
ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ãƒ•ã‚¡ã‚¯ãƒˆãƒª
å¤§å­¦ãƒ»å­¦éƒ¨ã«å¿œã˜ãŸé©åˆ‡ãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ç”Ÿæˆ
"""

from typing import Dict, Type, List, Optional
import logging

from scraper.domain.university import University
from scraper.application.scrapers.university_scraper_base import UniversityScraperBase
from scraper.application.scrapers.medical_scraper import MedicalLabScraper
from scraper.application.scrapers.agriculture_scraper import AgricultureLabScraper
from scraper.config.interfaces import ScrapingError

logger = logging.getLogger(__name__)


class ScraperFactory:
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ãƒ•ã‚¡ã‚¯ãƒˆãƒª"""
    
    def __init__(self):
        self._scraper_registry: Dict[str, Type[UniversityScraperBase]] = {
            'medical': MedicalLabScraper,
            'agriculture': AgricultureLabScraper,
            'veterinary': AgricultureLabScraper,  # è¾²å­¦ç³»ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’æµç”¨
            'general': UniversityScraperBase
        }
    
    def create_scraper(self, university: University, faculty_type: str = None) -> UniversityScraperBase:
        """
        å¤§å­¦ãƒ»å­¦éƒ¨ã«å¿œã˜ãŸã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ä½œæˆ
        
        Args:
            university: å¤§å­¦ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£
            faculty_type: å­¦éƒ¨ç¨®åˆ¥ï¼ˆè‡ªå‹•åˆ¤å®šã‚‚å¯èƒ½ï¼‰
        
        Returns:
            UniversityScraperBase: é©åˆ‡ãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼
        """
        try:
            # å­¦éƒ¨ç¨®åˆ¥ã®è‡ªå‹•åˆ¤å®š
            if not faculty_type:
                faculty_type = self._determine_faculty_type(university)
            
            # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹ã®é¸æŠ
            scraper_class = self._scraper_registry.get(faculty_type, UniversityScraperBase)
            
            # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ä½œæˆ
            scraper = scraper_class(university)
            
            logger.info(f"âœ… {university.name} ç”¨ {scraper_class.__name__} ã‚’ä½œæˆ")
            return scraper
            
        except Exception as e:
            logger.error(f"âŒ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ä½œæˆå¤±æ•— {university.name}: {e}")
            raise ScrapingError(f"Failed to create scraper for {university.name}: {e}")
    
    def create_multiple_scrapers(self, universities: List[University]) -> List[UniversityScraperBase]:
        """è¤‡æ•°å¤§å­¦ç”¨ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ä¸€æ‹¬ä½œæˆ"""
        scrapers = []
        
        for university in universities:
            try:
                scraper = self.create_scraper(university)
                scrapers.append(scraper)
            except Exception as e:
                logger.error(f"âŒ {university.name} ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—: {e}")
                continue
        
        logger.info(f"ğŸ­ {len(scrapers)}/{len(universities)} ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ä½œæˆ")
        return scrapers
    
    def _determine_faculty_type(self, university: University) -> str:
        """å¤§å­¦ã®ç‰¹å¾´ã‹ã‚‰å­¦éƒ¨ç¨®åˆ¥ã‚’è‡ªå‹•åˆ¤å®š"""
        university_name = university.name.lower()
        
        # è¾²å­¦ãƒ»ç£åŒ»å­¦ç³»å¤§å­¦
        agriculture_indicators = [
            'è¾²å·¥å¤§', 'è¾²æ¥­å¤§', 'ç•œç”£å¤§', 'ç£åŒ»å¤§',
            'agriculture', 'veterinary', 'livestock'
        ]
        
        if any(indicator in university_name for indicator in agriculture_indicators):
            return 'agriculture'
        
        # åŒ»ç§‘å¤§å­¦
        medical_indicators = [
            'åŒ»ç§‘å¤§', 'åŒ»å¤§', 'åŒ»ç™‚å¤§',
            'medical', 'medicine'
        ]
        
        if any(indicator in medical_indicators for indicator in medical_indicators):
            return 'medical'
        
        # å­¦éƒ¨æƒ…å ±ã‹ã‚‰åˆ¤å®š
        if university.has_medical_faculty() and university.has_agriculture_faculty():
            # ä¸¡æ–¹ã‚ã‚‹å ´åˆã¯ã€å„ªå…ˆåº¦ã§æ±ºå®šï¼ˆå…ç–«ç ”ç©¶ã®è¦³ç‚¹ï¼‰
            return 'medical'
        elif university.has_medical_faculty():
            return 'medical'
        elif university.has_agriculture_faculty():
            return 'agriculture'
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯åŒ»å­¦ç³»ï¼ˆå…ç–«ç ”ç©¶ã®ä¸»è¦åˆ†é‡ï¼‰
        return 'medical'
    
    def register_scraper(self, faculty_type: str, scraper_class: Type[UniversityScraperBase]) -> None:
        """æ–°ã—ã„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ç™»éŒ²"""
        self._scraper_registry[faculty_type] = scraper_class
        logger.info(f"ğŸ“ æ–°ã—ã„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’ç™»éŒ²: {faculty_type} -> {scraper_class.__name__}")
    
    def get_available_faculty_types(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªå­¦éƒ¨ç¨®åˆ¥ã‚’å–å¾—"""
        return list(self._scraper_registry.keys())
    
    def get_scraper_info(self) -> Dict[str, str]:
        """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼æƒ…å ±ã‚’å–å¾—"""
        return {
            faculty_type: scraper_class.__name__ 
            for faculty_type, scraper_class in self._scraper_registry.items()
        }


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ•ã‚¡ã‚¯ãƒˆãƒªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
scraper_factory = ScraperFactory()
