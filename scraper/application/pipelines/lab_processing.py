"""
ç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆãƒ»å¼·åŒ–ãƒ»å“è³ªç®¡ç†
"""

import asyncio
from typing import List, Dict, Optional, Tuple
import logging
from datetime import datetime

from scraper.config.interfaces import ResearchLabData, DataValidationError
from scraper.domain.research_lab import ResearchLab, create_research_lab_from_data
from scraper.domain.university import University
from scraper.domain.keyword_analyzer import keyword_analyzer
from scraper.config.settings import quality_settings

logger = logging.getLogger(__name__)


class LabDataProcessor:
    """ç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    def __init__(self):
        self.processed_count = 0
        self.rejected_count = 0
        self.duplicate_count = 0
        self.enhanced_count = 0
    
    async def process_lab_data_batch(
        self, 
        raw_labs: List[ResearchLabData],
        university: University
    ) -> List[ResearchLab]:
        """ç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒå‡¦ç†"""
        logger.info(f"ğŸ”„ {university.name}: {len(raw_labs)}ä»¶ã®ç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹")
        
        # Step 1: åŸºæœ¬ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        validated_labs = await self._validate_basic_requirements(raw_labs)
        logger.info(f"ğŸ“‹ åŸºæœ¬ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³: {len(validated_labs)}/{len(raw_labs)}ä»¶åˆæ ¼")
        
        # Step 2: é‡è¤‡é™¤å»
        deduplicated_labs = await self._remove_duplicates(validated_labs)
        self.duplicate_count += len(validated_labs) - len(deduplicated_labs)
        logger.info(f"ğŸ” é‡è¤‡é™¤å»: {len(deduplicated_labs)}ä»¶ï¼ˆ{self.duplicate_count}ä»¶é™¤å»ï¼‰")
        
        # Step 3: ãƒ‡ãƒ¼ã‚¿å¼·åŒ–
        enhanced_labs = await self._enhance_lab_data(deduplicated_labs, university)
        logger.info(f"âš¡ ãƒ‡ãƒ¼ã‚¿å¼·åŒ–: {len(enhanced_labs)}ä»¶")
        
        # Step 4: å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        quality_filtered_labs = await self._filter_by_quality(enhanced_labs)
        self.rejected_count += len(enhanced_labs) - len(quality_filtered_labs)
        logger.info(f"ğŸ¯ å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: {len(quality_filtered_labs)}ä»¶ï¼ˆ{len(enhanced_labs) - len(quality_filtered_labs)}ä»¶é™¤å¤–ï¼‰")
        
        # Step 5: ResearchLabã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä½œæˆ
        research_labs = await self._create_research_lab_entities(quality_filtered_labs, university)
        self.processed_count += len(research_labs)
        
        logger.info(f"âœ… {university.name}: {len(research_labs)}ä»¶ã®ç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†")
        return research_labs
    
    async def _validate_basic_requirements(self, labs: List[ResearchLabData]) -> List[ResearchLabData]:
        """åŸºæœ¬è¦ä»¶ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        validated_labs = []
        
        for lab in labs:
            try:
                # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
                if not lab.name or len(lab.name.strip()) < 3:
                    continue
                
                if not lab.professor_name or len(lab.professor_name.strip()) < 2:
                    continue
                
                if not lab.research_content or len(lab.research_content) < quality_settings.min_content_length:
                    continue
                
                # ç ”ç©¶å†…å®¹ã®è³ªãƒã‚§ãƒƒã‚¯
                if not self._is_meaningful_content(lab.research_content):
                    continue
                
                validated_labs.append(lab)
                
            except Exception as e:
                logger.warning(f"åŸºæœ¬ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: {e}")
                continue
        
        return validated_labs
    
    def _is_meaningful_content(self, content: str) -> bool:
        """ç ”ç©¶å†…å®¹ãŒæ„å‘³ã®ã‚ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ãƒã‚§ãƒƒã‚¯"""
        if not content:
            return False
        
        # æœ€å°æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯
        if len(content) < 50:
            return False
        
        # æ„å‘³ã®ã‚ã‚‹å˜èªã®æ•°ã‚’ãƒã‚§ãƒƒã‚¯
        meaningful_words = [
            'ç ”ç©¶', 'research', 'é–‹ç™º', 'development', 'è§£æ', 'analysis',
            'å®Ÿé¨“', 'experiment', 'æ¤œè¨', 'èª¿æŸ»', 'investigation',
            'æŠ€è¡“', 'technology', 'æ‰‹æ³•', 'method', 'ç†è«–', 'theory'
        ]
        
        word_count = sum(1 for word in meaningful_words if word.lower() in content.lower())
        return word_count >= 2
    
    async def _remove_duplicates(self, labs: List[ResearchLabData]) -> List[ResearchLabData]:
        """é‡è¤‡ç ”ç©¶å®¤ã®é™¤å»"""
        seen_signatures = set()
        unique_labs = []
        
        for lab in labs:
            # é‡è¤‡åˆ¤å®šã®ã‚·ã‚°ãƒãƒãƒ£ä½œæˆ
            signature = self._create_lab_signature(lab)
            
            if signature not in seen_signatures:
                seen_signatures.add(signature)
                unique_labs.append(lab)
        
        return unique_labs
    
    def _create_lab_signature(self, lab: ResearchLabData) -> str:
        """ç ”ç©¶å®¤ã®é‡è¤‡åˆ¤å®šç”¨ã‚·ã‚°ãƒãƒãƒ£ä½œæˆ"""
        # ç ”ç©¶å®¤åã¨æ•™æˆåã‚’æ­£è¦åŒ–ã—ã¦çµåˆ
        normalized_name = self._normalize_text(lab.name)
        normalized_professor = self._normalize_text(lab.professor_name)
        
        return f"{normalized_name}#{normalized_professor}#{lab.university_id}"
    
    def _normalize_text(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã®æ­£è¦åŒ–"""
        if not text:
            return ""
        
        # å°æ–‡å­—åŒ–ã€ç©ºç™½é™¤å»ã€è¨˜å·é™¤å»
        import re
        normalized = re.sub(r'[^\w\s]', '', text.lower())
        normalized = re.sub(r'\s+', '', normalized)
        
        return normalized
    
    async def _enhance_lab_data(self, labs: List[ResearchLabData], university: University) -> List[ResearchLabData]:
        """ãƒ‡ãƒ¼ã‚¿å¼·åŒ–å‡¦ç†"""
        enhanced_labs = []
        
        for lab in labs:
            try:
                enhanced_lab = await self._enhance_single_lab(lab, university)
                enhanced_labs.append(enhanced_lab)
                self.enhanced_count += 1
                
            except Exception as e:
                logger.warning(f"ãƒ‡ãƒ¼ã‚¿å¼·åŒ–å¤±æ•— {lab.name}: {e}")
                # å¼·åŒ–ã«å¤±æ•—ã—ã¦ã‚‚ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ã¯ä¿æŒ
                enhanced_labs.append(lab)
        
        return enhanced_labs
    
    async def _enhance_single_lab(self, lab: ResearchLabData, university: University) -> ResearchLabData:
        """å˜ä¸€ç ”ç©¶å®¤ã®ãƒ‡ãƒ¼ã‚¿å¼·åŒ–"""
        enhanced_lab = lab
        
        # å…ç–«é–¢é€£åº¦åˆ†æ
        if lab.research_content:
            analysis_result = keyword_analyzer.analyze_content(lab.research_content)
            
            enhanced_lab.immune_relevance_score = analysis_result.immune_relevance_score
            enhanced_lab.research_field = analysis_result.field_classification
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ±åˆ
            if analysis_result.matched_keywords:
                existing_keywords = lab.keywords or ''
                new_keywords = ', '.join(analysis_result.matched_keywords)
                enhanced_lab.keywords = f"{existing_keywords}, {new_keywords}".strip(', ')
            
            # å‹•ç‰©ç¨®ãƒ»æ¤ç‰©ç¨®æƒ…å ±
            if analysis_result.animal_species:
                enhanced_lab.animal_species = ', '.join(analysis_result.animal_species)
            
            if analysis_result.plant_species:
                enhanced_lab.plant_species = ', '.join(analysis_result.plant_species)
        
        # å¤§å­¦æƒ…å ±ã®çµ±åˆ
        enhanced_lab.university_id = university.info.id
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
        if not enhanced_lab.metadata:
            enhanced_lab.metadata = {}
        
        enhanced_lab.metadata.update({
            'processed_at': datetime.now().isoformat(),
            'university_tier': 1 if university.is_tier1_university() else 2 if university.is_tier2_university() else 3,
            'university_type': university.type.value,
            'university_region': university.region
        })
        
        return enhanced_lab
    
    async def _filter_by_quality(self, labs: List[ResearchLabData]) -> List[ResearchLabData]:
        """å“è³ªåŸºæº–ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        quality_labs = []
        
        for lab in labs:
            try:
                quality_score = self._calculate_quality_score(lab)
                
                # å“è³ªã‚¹ã‚³ã‚¢ãŒåŸºæº–ã‚’æº€ãŸã™å ´åˆã®ã¿é€šã™
                if quality_score >= 0.6:  # 60%ä»¥ä¸Šã®å“è³ªã‚¹ã‚³ã‚¢
                    if not lab.metadata:
                        lab.metadata = {}
                    lab.metadata['quality_score'] = quality_score
                    quality_labs.append(lab)
                
            except Exception as e:
                logger.warning(f"å“è³ªè©•ä¾¡å¤±æ•— {lab.name}: {e}")
                continue
        
        return quality_labs
    
    def _calculate_quality_score(self, lab: ResearchLabData) -> float:
        """ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—"""
        score = 0.0
        total_weight = 0.0
        
        # åŸºæœ¬æƒ…å ±ã®å®Œå…¨æ€§ï¼ˆ50%ï¼‰
        if lab.name and len(lab.name) > 5:
            score += 0.2; total_weight += 0.2
        if lab.professor_name and len(lab.professor_name) > 2:
            score += 0.15; total_weight += 0.15
        if lab.research_content and len(lab.research_content) > 100:
            score += 0.15; total_weight += 0.15
        
        # è©³ç´°æƒ…å ±ã®å……å®Ÿåº¦ï¼ˆ30%ï¼‰
        if lab.keywords and len(lab.keywords.split(',')) >= 3:
            score += 0.15; total_weight += 0.15
        if lab.lab_url:
            score += 0.15; total_weight += 0.15
        
        # å…ç–«é–¢é€£åº¦ï¼ˆ20%ï¼‰
        if lab.immune_relevance_score and lab.immune_relevance_score >= quality_settings.min_immune_relevance_score:
            score += 0.2; total_weight += 0.2
        
        return score / total_weight if total_weight > 0 else 0.0
    
    async def _create_research_lab_entities(self, labs: List[ResearchLabData], university: University) -> List[ResearchLab]:
        """ResearchLabã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ä½œæˆ"""
        research_labs = []
        
        for lab_data in labs:
            try:
                research_lab = create_research_lab_from_data(
                    data=lab_data,
                    university_info=university.info
                )
                research_labs.append(research_lab)
                
            except Exception as e:
                logger.error(f"ResearchLabã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä½œæˆå¤±æ•— {lab_data.name}: {e}")
                continue
        
        return research_labs
    
    def get_processing_stats(self) -> Dict[str, int]:
        """å‡¦ç†çµ±è¨ˆã‚’å–å¾—"""
        return {
            'processed_count': self.processed_count,
            'rejected_count': self.rejected_count,
            'duplicate_count': self.duplicate_count,
            'enhanced_count': self.enhanced_count
        }
