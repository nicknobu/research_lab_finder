# ğŸ”¬ ç ”ç©¶å®¤ãƒ•ã‚¡ã‚¤ãƒ³ãƒ€ãƒ¼ - Python 3.9 ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

# ==================== Step 1: ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ ====================
# Python 3.9å¯¾å¿œç‰ˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆä¸Šè¨˜ä½œæˆæ¸ˆã¿ï¼‰
chmod +x scripts/setup_python39_compatible.sh
./scripts/setup_python39_compatible.sh

# ==================== Step 2: ä»®æƒ³ç’°å¢ƒæœ‰åŠ¹åŒ– ====================
# Windows (Git Bash)
source venv/Scripts/activate

# Linux/macOS (å‚è€ƒ)
# source venv/bin/activate

# ==================== Step 3: Python 3.9å¯¾å¿œä¾å­˜é–¢ä¿‚ä½œæˆ ====================
# requirements/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ä½œæˆæ¸ˆã¿
# ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‰‹å‹•ã§ä½œæˆï¼ˆClaudeãŒæä¾›ï¼‰

# ---- requirements/base.txt (Python 3.9ç‰ˆ) ----
cat > requirements/base.txt << 'EOF'
# ğŸ”¬ Python 3.9å¯¾å¿œç‰ˆ - å…±é€šä¾å­˜é–¢ä¿‚
pydantic>=1.10,<2.0
pydantic[dotenv]>=1.10,<2.0
pandas>=1.5,<2.0
numpy>=1.21,<2.0
python-dateutil>=2.8,<3.0
python-dotenv>=0.20,<1.0
structlog>=22.3,<24.0
click>=8.0,<9.0
rich>=12.0,<14.0
sqlalchemy>=1.4,<2.0
alembic>=1.8,<2.0
httpx>=0.23,<1.0
cryptography>=3.4,<42.0
tqdm>=4.60,<5.0
colorama>=0.4,<1.0
typing-extensions>=4.0,<5.0
pyyaml>=6.0,<7.0
ujson>=5.4,<6.0
EOF

# ---- requirements/backend.txt (Python 3.9ç‰ˆ) ----
cat > requirements/backend.txt << 'EOF'
# ğŸ”¬ Python 3.9å¯¾å¿œç‰ˆ - ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ä¾å­˜é–¢ä¿‚
-r base.txt

# Web Framework
fastapi>=0.95,<1.0
uvicorn[standard]>=0.20,<1.0
gunicorn>=20.1,<22.0

# Database Specific
psycopg2-binary>=2.9,<3.0
pgvector>=0.1.6,<1.0
asyncpg>=0.27,<1.0

# AI & Machine Learning
openai>=0.28,<1.0
scikit-learn>=1.2,<2.0

# HTTP & API
python-multipart>=0.0.5,<1.0
python-jose[cryptography]>=3.3,<4.0
passlib[bcrypt]>=1.7,<2.0

# Performance
aiofiles>=22.1,<24.0
prometheus-client>=0.16,<1.0
EOF

# ---- requirements/scraper.txt (Python 3.9ç‰ˆ) ----
cat > requirements/scraper.txt << 'EOF'
# ğŸ”¬ Python 3.9å¯¾å¿œç‰ˆ - ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¾å­˜é–¢ä¿‚
-r base.txt

# HTTP & Web Scraping
aiohttp>=3.8,<4.0
asyncio-throttle>=1.0.2,<2.0
tenacity>=8.0,<9.0
fake-useragent>=1.4,<2.0

# HTML Parsing
beautifulsoup4>=4.11,<5.0
lxml>=4.6,<5.0
pyquery>=1.4,<3.0

# Async & Concurrency
aiofiles>=22.1,<24.0
schedule>=1.2,<2.0

# Dependency Injection
dependency-injector>=4.40,<5.0

# Monitoring & Metrics
psutil>=5.9,<6.0
memory-profiler>=0.60,<1.0

# Data Storage & Export
openpyxl>=3.0,<4.0
jsonlines>=3.1,<5.0

# Caching
diskcache>=5.4,<6.0
cachetools>=5.0,<6.0

# Text Processing
spacy>=3.4,<4.0
fuzzywuzzy>=0.18,<1.0

# CLI
typer>=0.7,<1.0
EOF

# ---- requirements/dev.txt (Python 3.9ç‰ˆ) ----
cat > requirements/dev.txt << 'EOF'
# ğŸ”¬ Python 3.9å¯¾å¿œç‰ˆ - é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆä¾å­˜é–¢ä¿‚
-r base.txt
-r backend.txt
-r scraper.txt

# Testing Framework
pytest>=7.1,<8.0
pytest-asyncio>=0.20,<1.0
pytest-cov>=4.0,<5.0
pytest-mock>=3.10,<4.0
hypothesis>=6.60,<7.0

# Code Quality
mypy>=0.991,<2.0
black>=22.0,<24.0
isort>=5.10,<6.0
flake8>=5.0,<7.0
bandit>=1.7,<2.0

# Development Tools
pre-commit>=2.20,<4.0
ipython>=8.5,<9.0
jupyter>=1.0,<2.0

# Documentation
sphinx>=5.0,<8.0
sphinx-rtd-theme>=1.0,<2.0
EOF

# ==================== Step 4: ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« ====================
# pip ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
pip install --upgrade pip

# åŸºæœ¬ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements/base.txt

# ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements/backend.txt

# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements/scraper.txt

# é–‹ç™ºä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
# pip install -r requirements/dev.txt

# ==================== Step 5: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ä¾å­˜é–¢ä¿‚ ====================
cd frontend
npm install
cd ..

# ==================== Step 6: ç’°å¢ƒå¤‰æ•°è¨­å®š ====================
# .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†
echo "ğŸ“ .env ãƒ•ã‚¡ã‚¤ãƒ«ã§OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„"
echo "OPENAI_API_KEY=sk-your_actual_api_key_here"

# ==================== Step 7: æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª ====================
# Docker ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•
docker-compose up -d

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
sleep 10
curl http://localhost:8000/health

# ==================== Step 8: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆæœŸåŒ– ====================
# åŸºæœ¬çš„ãªPythonãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
mkdir -p scraper/config scraper/domain

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆClaudeæä¾›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ï¼‰
echo "ğŸ“ scraper/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ãŒä½œæˆã•ã‚Œã¾ã—ãŸ"
echo "ğŸ’¡ Claude ãŒä½œæˆã—ãŸä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ï¼š"
echo "  - scraper/config/interfaces.py"
echo "  - scraper/config/settings.py"
echo "  - scraper/domain/research_lab.py"

# ==================== å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ ====================
echo ""
echo "ğŸ‰ Python 3.9å¯¾å¿œã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†ï¼"
echo ""
echo "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼š"
echo "1. Claudeä½œæˆã® scraper/ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®"
echo "2. .env ãƒ•ã‚¡ã‚¤ãƒ«ã§APIã‚­ãƒ¼è¨­å®š"
echo "3. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½é–‹ç™ºé–‹å§‹"